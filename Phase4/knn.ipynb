{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Concept-of-the-$k$-Nearest-Neighbors-Algorithm\" data-toc-modified-id=\"Concept-of-the-$k$-Nearest-Neighbors-Algorithm-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Concept of the $k$-Nearest Neighbors Algorithm</a></span><ul class=\"toc-item\"><li><span><a href=\"#Who's-Nearby?\" data-toc-modified-id=\"Who's-Nearby?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Who's Nearby?</a></span></li><li><span><a href=\"#Summary-of-$k$NN\" data-toc-modified-id=\"Summary-of-$k$NN-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Summary of $k$NN</a></span></li><li><span><a href=\"#Implementing-in-Scikit-Learn\" data-toc-modified-id=\"Implementing-in-Scikit-Learn-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Implementing in Scikit-Learn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-the-KNN\" data-toc-modified-id=\"Training-the-KNN-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Training the KNN</a></span></li><li><span><a href=\"#Make-Some-Predictions\" data-toc-modified-id=\"Make-Some-Predictions-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Make Some Predictions</a></span></li></ul></li></ul></li><li><span><a href=\"#The-Pros-and-Cons\" data-toc-modified-id=\"The-Pros-and-Cons-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The Pros and Cons</a></span><ul class=\"toc-item\"><li><span><a href=\"#Advantages\" data-toc-modified-id=\"Advantages-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Advantages</a></span></li><li><span><a href=\"#Disadvantages\" data-toc-modified-id=\"Disadvantages-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Disadvantages</a></span></li></ul></li><li><span><a href=\"#Classification-with-sklearn.neighbors\" data-toc-modified-id=\"Classification-with-sklearn.neighbors-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Classification with <code>sklearn.neighbors</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Train-Test Split</a></span></li><li><span><a href=\"#Validation-Split\" data-toc-modified-id=\"Validation-Split-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Validation Split</a></span></li><li><span><a href=\"#Different-$k$-Values\" data-toc-modified-id=\"Different-$k$-Values-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Different $k$ Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#$k=1$\" data-toc-modified-id=\"$k=1$-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>$k=1$</a></span></li><li><span><a href=\"#$k=3$\" data-toc-modified-id=\"$k=3$-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>$k=3$</a></span></li><li><span><a href=\"#$k=5$\" data-toc-modified-id=\"$k=5$-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>$k=5$</a></span></li><li><span><a href=\"#Observing-Different-$k$-Values\" data-toc-modified-id=\"Observing-Different-$k$-Values-4.3.4\"><span class=\"toc-item-num\">4.3.4&nbsp;&nbsp;</span>Observing Different $k$ Values</a></span></li></ul></li><li><span><a href=\"#Scaling\" data-toc-modified-id=\"Scaling-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Scaling</a></span><ul class=\"toc-item\"><li><span><a href=\"#More-Resources-on-Scaling\" data-toc-modified-id=\"More-Resources-on-Scaling-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>More Resources on Scaling</a></span></li></ul></li></ul></li><li><span><a href=\"#$k$-and-the-Bias-Variance-Tradeoff\" data-toc-modified-id=\"$k$-and-the-Bias-Variance-Tradeoff-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>$k$ and the Bias-Variance Tradeoff</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Relation-Between-$k$-and-Bias/Variance\" data-toc-modified-id=\"The-Relation-Between-$k$-and-Bias/Variance-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>The Relation Between $k$ and Bias/Variance</a></span></li></ul></li><li><span><a href=\"#Level-Up:-Distance-Metrics\" data-toc-modified-id=\"Level-Up:-Distance-Metrics-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Level Up: Distance Metrics</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wilson](images/wilson.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.088306Z",
     "start_time": "2023-06-05T16:52:26.397133Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix,\\\n",
    "recall_score, precision_score, accuracy_score, plot_confusion_matrix\n",
    "from src.k_classify import predict_one\n",
    "from src.plot_train import *\n",
    "from src.euclid import *\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Describe the $k$-nearest neighbors algorithm\n",
    "- Identify multiple common distance metrics\n",
    "- Tune $k$ appropriately in response to models with high bias or variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Concept of the $k$-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First let's recall what is **supervised learning**.\n",
    "\n",
    "> In **supervised learning** we use example data (_training data_) to inform our predictions of future data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that this definition includes _classification_ and _regression_ problems. And there are a variety of ways we  can make predictions from past data.\n",
    "\n",
    "$k$-nearest neighbors is one such method of making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Who's Nearby?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One strategy to make predictions on a new data is to just look at what _similar_ data points are like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/best_k_fs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can say _nearby_ points are _similar_ to one another. There are a few different wasy to determine how \"close\" data points are to one another. Check out the [Level Up section on distance metrics](#Level-Up:-Distance-Metrics) for some more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Summary of $k$NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/knn-process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Implementing in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) & [`KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try doing some basic classification on some data using the KNN algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.118307Z",
     "start_time": "2023-06-05T16:52:32.090308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "display(iris)\n",
    "# Let's convert this over to NumPy array\n",
    "X = iris.iloc[:, :2].to_numpy()\n",
    "# Let's convert classes to numerical values\n",
    "y = LabelEncoder().fit_transform(iris['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.134308Z",
     "start_time": "2023-06-05T16:52:32.120308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.383306Z",
     "start_time": "2023-06-05T16:52:32.137308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], ax=ax, hue=y, palette='colorblind')\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training the KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.399308Z",
     "start_time": "2023-06-05T16:52:32.385309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "neigh.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Make Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.414307Z",
     "start_time": "2023-06-05T16:52:32.400308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Made up data points\n",
    "pred_pts = np.array([\n",
    "    [7.0, 3.0],\n",
    "    [8.0, 3.5],\n",
    "    [7.0, 4.0],    \n",
    "    [4.0, 3.0],\n",
    "    [5.0, 3.0],\n",
    "    [5.5, 4.0],\n",
    "    [5.0, 2.0],\n",
    "    [6.0, 2.5],\n",
    "    [5.8, 3.5],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see these new points against the training data. Think about how they'll be made classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.570307Z",
     "start_time": "2023-06-05T16:52:32.415306Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], ax=ax, hue=y, palette='colorblind')\n",
    "sns.scatterplot(x=pred_pts[:, 0], ax=ax, y=pred_pts[:, 1], marker=\"*\",\n",
    "                s=200, edgecolor='black', color='magenta')\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.586307Z",
     "start_time": "2023-06-05T16:52:32.572309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "pred_y = neigh.predict(pred_pts)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.601307Z",
     "start_time": "2023-06-05T16:52:32.588308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Probabilities for KNN (how they voted)\n",
    "for p,prob in zip(pred_y,neigh.predict_proba(pred_pts)):\n",
    "    print(f'{p}: {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.772334Z",
     "start_time": "2023-06-05T16:52:32.604308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X[:, 0],y=X[:, 1], ax=ax, hue=y, palette='colorblind')\n",
    "sns.scatterplot(x=pred_pts[:, 0], ax=ax, y=pred_pts[:, 1],\n",
    "                hue=pred_y, palette='colorblind', marker=\"*\", s=200, edgecolor='black')\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see those predictions plotted with the other points after the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The Pros and Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Models have different use cases and it helps to understand the strengths and weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Lazy learning (no training phase)\n",
    "- Simple algorithm to understand and implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Has to be kept in memory (small data with few features)\n",
    "- Not robust; doesn't generalize well\n",
    "- Soft boundaries are troublesome\n",
    "- \"Curse of Dimensionality\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with `sklearn.neighbors`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$k$-Nearest Neighbors is a modeling technique that works for both regression and classification problems. Here we'll apply it to a version of the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.804309Z",
     "start_time": "2023-06-05T16:52:32.774308Z"
    }
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/cleaned_titanic.csv')\n",
    "titanic = titanic.iloc[:, :-2]\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For visualization purposes, we will use only two features for our first model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.820332Z",
     "start_time": "2023-06-05T16:52:32.805308Z"
    }
   },
   "outputs": [],
   "source": [
    "X = titanic[['Age', 'Fare']]\n",
    "y = titanic['Survived']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset of course presents a binary classification problem, with our target being the `Survived` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.836311Z",
     "start_time": "2023-06-05T16:52:32.822308Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:32.851334Z",
     "start_time": "2023-06-05T16:52:32.838309Z"
    }
   },
   "outputs": [],
   "source": [
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train,\n",
    "                                          random_state=42,\n",
    "                                          test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.119306Z",
     "start_time": "2023-06-05T16:52:32.852308Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_t, y_t)\n",
    "print(f\"training accuracy: {knn.score(X_t, y_t)}\")\n",
    "print(f\"validation accuracy: {knn.score(X_val, y_val)}\")\n",
    "\n",
    "plot_confusion_matrix(estimator=knn, X=X_t, y_true=y_t, display_labels=['Perished', 'Survived'])\n",
    "plot_confusion_matrix(estimator=knn, X=X_val, y_true=y_val, display_labels=['Perished', 'Survived']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.290308Z",
     "start_time": "2023-06-05T16:52:33.121308Z"
    }
   },
   "outputs": [],
   "source": [
    "X_for_viz = X_t.sample(15, random_state=40)\n",
    "y_for_viz = y_t[X_for_viz.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.scatterplot(x=X_for_viz['Age'], y=X_for_viz['Fare'], \n",
    "                hue=y_for_viz, palette={0: 'red', 1: 'green'}, \n",
    "                s=200, ax=ax)\n",
    "\n",
    "ax.set_xlim(0, 80)\n",
    "ax.set_ylim(0, 80)\n",
    "plt.legend()\n",
    "plt.title('Subsample of Training Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $k$-NN algorithm works by simply storing the training set in memory, then measuring the distance from the training points to a new point.\n",
    "\n",
    "Let's drop a point from our validation set into the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.444337Z",
     "start_time": "2023-06-05T16:52:33.291308Z"
    }
   },
   "outputs": [],
   "source": [
    "X_for_viz = X_t.sample(15, random_state=40)\n",
    "y_for_viz = y_t[X_for_viz.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.scatterplot(x=X_for_viz['Age'], y=X_for_viz['Fare'],\n",
    "                hue=y_for_viz, palette={0: 'red', 1: 'green'},\n",
    "                s=200, ax=ax)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#################^^^Old code^^^##############\n",
    "####################New code#################\n",
    "\n",
    "# Let's take one sample from our validation set and plot it\n",
    "new_x = pd.DataFrame(X_val.loc[484]).T\n",
    "new_y = y_val[new_x.index]\n",
    "\n",
    "sns.scatterplot(x=new_x['Age'], y=new_x['Fare'], color='blue',\n",
    "                s=200, ax=ax, label='New', marker='P')\n",
    "\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.460307Z",
     "start_time": "2023-06-05T16:52:33.445308Z"
    }
   },
   "outputs": [],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, $k$-NN finds the $k$ nearest points. $k$ corresponds to the `n_neighbors` parameter defined when we instantiate the classifier object. **If $k$ = 1, then the prediction for a point will simply be the value of the target for the nearest point.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different $k$ Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big factor in this algorithm is choosing $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/k_vs_errors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.475334Z",
     "start_time": "2023-06-05T16:52:33.462309Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our training data, then predict what our validation point will be based on the (one) closest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.491344Z",
     "start_time": "2023-06-05T16:52:33.476307Z"
    }
   },
   "outputs": [],
   "source": [
    "knn.fit(X_for_viz, y_for_viz)\n",
    "knn.predict(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When we raise the value of $k$, $k$-NN will act democratically: It will find the $k$ closest points, and take a vote based on the labels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's raise $k$ to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.506336Z",
     "start_time": "2023-06-05T16:52:33.493309Z"
    }
   },
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.522332Z",
     "start_time": "2023-06-05T16:52:33.507309Z"
    }
   },
   "outputs": [],
   "source": [
    "knn3.fit(X_for_viz, y_for_viz)\n",
    "knn3.predict(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not easy to tell what which points are closest by eye.\n",
    "\n",
    "Let's update our plot to add indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.755312Z",
     "start_time": "2023-06-05T16:52:33.524308Z"
    }
   },
   "outputs": [],
   "source": [
    "X_for_viz = X_t.sample(15, random_state=40)\n",
    "y_for_viz = y_t[X_for_viz.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.scatterplot(x=X_for_viz['Age'], y=X_for_viz['Fare'], hue=y_for_viz, \n",
    "                palette={0: 'red', 1: 'green'}, s=200, ax=ax)\n",
    "\n",
    "\n",
    "# Now let's take another sample\n",
    "\n",
    "# new_x = X_val.sample(1, random_state=33)\n",
    "new_x = pd.DataFrame(X_val.loc[484]).T\n",
    "new_x.columns = ['Age', 'Fare']\n",
    "new_y = y_val[new_x.index]\n",
    "\n",
    "print(new_x)\n",
    "sns.scatterplot(x=new_x['Age'], y=new_x['Fare'], color='blue', \n",
    "                s=200, ax=ax, label='New', marker='P')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "plt.legend()\n",
    "\n",
    "#################^^^Old code^^^##############\n",
    "####################New code#################\n",
    "\n",
    "# add annotations one by one with a loop\n",
    "for index in X_for_viz.index:\n",
    "    ax.text(X_for_viz.Age[index]+0.7, X_for_viz.Fare[index],\n",
    "            s=index, horizontalalignment='left', size='medium',\n",
    "            color='black', weight='semibold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `sklearn`'s NearestNeighors object to see the exact calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.771315Z",
     "start_time": "2023-06-05T16:52:33.756307Z"
    }
   },
   "outputs": [],
   "source": [
    "df_for_viz = pd.merge(X_for_viz, y_for_viz, left_index=True, right_index=True)\n",
    "neighbor = NearestNeighbors(n_neighbors=3)\n",
    "neighbor.fit(X_for_viz)\n",
    "nearest = neighbor.kneighbors(new_x)\n",
    "\n",
    "nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.787342Z",
     "start_time": "2023-06-05T16:52:33.772337Z"
    }
   },
   "outputs": [],
   "source": [
    "df_for_viz.iloc[nearest[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.803360Z",
     "start_time": "2023-06-05T16:52:33.788340Z"
    }
   },
   "outputs": [],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.819360Z",
     "start_time": "2023-06-05T16:52:33.805308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use Euclidean distance to see how close they are to this point\n",
    "print(((29-24)**2 + (33-25.4667)**2)**0.5)\n",
    "print(((26-24)**2 + (16.1-25.4667)**2)**0.5)\n",
    "print(((20-24)**2 + (15.7417-25.4667)**2)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with five neighbors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.835309Z",
     "start_time": "2023-06-05T16:52:33.825309Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_for_viz, y_for_viz)\n",
    "knn.predict(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing Different $k$ Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate through $k$, odd numbers 1 through 10, and see the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.913308Z",
     "start_time": "2023-06-05T16:52:33.836311Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in range(1, 10, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_for_viz, y_for_viz)\n",
    "    print(f'k={k}', knn.predict(new_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which models were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.929352Z",
     "start_time": "2023-06-05T16:52:33.914308Z"
    }
   },
   "outputs": [],
   "source": [
    "new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have suspected that we were leaving something out. For any distance-based algorithms, scaling is very important. Look at how the shape of the array changes before and after scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![non-normal](images/nonnormal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![normal](images/normalized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our data_for_viz dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:33.975341Z",
     "start_time": "2023-06-05T16:52:33.931307Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train,\n",
    "                                          random_state=42,\n",
    "                                          test_size=0.25)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_ind = X_t.index\n",
    "X_col = X_t.columns\n",
    "\n",
    "X_t_s = pd.DataFrame(ss.fit_transform(X_t))\n",
    "X_t_s.index = X_ind\n",
    "X_t_s.columns = X_col\n",
    "\n",
    "X_v_ind = X_val.index\n",
    "X_val_s = pd.DataFrame(ss.transform(X_val))\n",
    "X_val_s.index = X_v_ind\n",
    "X_val_s.columns = X_col\n",
    "\n",
    "knn.fit(X_t_s, y_t)\n",
    "print(f\"training accuracy: {knn.score(X_t_s, y_t)}\")\n",
    "print(f\"Val accuracy: {knn.score(X_val_s, y_val)}\")\n",
    "\n",
    "y_hat = knn.predict(X_val_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:34.321333Z",
     "start_time": "2023-06-05T16:52:33.976307Z"
    }
   },
   "outputs": [],
   "source": [
    "# The plot_train() function just does what we did above.\n",
    "\n",
    "plot_train(X_t, y_t, X_val, y_val)\n",
    "plot_train(X_t_s, y_t, X_val_s, y_val, -2, 2, text_pos=0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how much that changes things.\n",
    "\n",
    "Look at points 166 and 150.  \n",
    "Look at the group 621, 143, and 191."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our classifier on scaled data and compare to unscaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:34.369339Z",
     "start_time": "2023-06-05T16:52:34.323332Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train,\n",
    "                                          random_state=42,\n",
    "                                          test_size=0.25)\n",
    "\n",
    "# The predict_one() function prints predictions on a given point\n",
    "# (#484) for k-nn models with k ranging from 1 to 10.\n",
    "\n",
    "predict_one(X_t, X_val, y_t, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:34.416740Z",
     "start_time": "2023-06-05T16:52:34.370339Z"
    }
   },
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "\n",
    "X_t_s = pd.DataFrame(mm.fit_transform(X_t))\n",
    "X_t_s.index = X_t.index\n",
    "X_t_s.columns = X_t.columns\n",
    "\n",
    "X_val_s = pd.DataFrame(mm.transform(X_val))\n",
    "X_val_s.index = X_val.index\n",
    "X_val_s.columns = X_val.columns\n",
    "\n",
    "\n",
    "predict_one(X_t_s, X_val_s, y_t, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### More Resources on Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://sebastianraschka.com/Articles/2014_about_feature_scaling.html   \n",
    "http://datareality.blogspot.com/2016/11/scaling-normalizing-standardizing-which.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$ and the Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:34.432740Z",
     "start_time": "2023-06-05T16:52:34.417739Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:36.264741Z",
     "start_time": "2023-06-05T16:52:34.433741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's slowly increase k and see what happens to our accuracy scores.\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "k_scores_train = {}\n",
    "k_scores_val = {}\n",
    "\n",
    "\n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    accuracy_score_t = []\n",
    "    accuracy_score_v = []\n",
    "    for train_ind, val_ind in kf.split(X_train, y_train):\n",
    "        \n",
    "        X_t, y_t = X_train.iloc[train_ind], y_train.iloc[train_ind] \n",
    "        X_v, y_v = X_train.iloc[val_ind], y_train.iloc[val_ind]\n",
    "        mm = MinMaxScaler()\n",
    "        \n",
    "        X_t_ind = X_t.index\n",
    "        X_v_ind = X_v.index\n",
    "        \n",
    "        X_t = pd.DataFrame(mm.fit_transform(X_t))\n",
    "        X_t.index = X_t_ind\n",
    "        X_v = pd.DataFrame(mm.transform(X_v))\n",
    "        X_v.index = X_v_ind\n",
    "        \n",
    "        knn.fit(X_t, y_t)\n",
    "        \n",
    "        y_pred_t = knn.predict(X_t)\n",
    "        y_pred_v = knn.predict(X_v)\n",
    "        \n",
    "        accuracy_score_t.append(accuracy_score(y_t, y_pred_t))\n",
    "        accuracy_score_v.append(accuracy_score(y_v, y_pred_v))\n",
    "        \n",
    "        \n",
    "    k_scores_train[k] = np.mean(accuracy_score_t)\n",
    "    k_scores_val[k] = np.mean(accuracy_score_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:36.280741Z",
     "start_time": "2023-06-05T16:52:36.265740Z"
    }
   },
   "outputs": [],
   "source": [
    "k_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:36.295765Z",
     "start_time": "2023-06-05T16:52:36.281740Z"
    }
   },
   "outputs": [],
   "source": [
    "k_scores_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:36.498740Z",
     "start_time": "2023-06-05T16:52:36.297740Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.plot(list(k_scores_train.keys()), list(k_scores_train.values()),\n",
    "        color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10, label='Train')\n",
    "ax.plot(list(k_scores_val.keys()), list(k_scores_val.values()),\n",
    "        color='green', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10, label='Val')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The Relation Between $k$ and Bias/Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Small $k$ values leads to overfitting, but larger $k$ values tend towards underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![alt text](images/K-NN_Neighborhood_Size_print.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> From [Machine Learning Flashcards](https://machinelearningflashcards.com/) by Chris Albon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:36.623776Z",
     "start_time": "2023-06-05T16:52:36.499740Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "\n",
    "X_train_ind = X_train.index\n",
    "X_train = pd.DataFrame(mm.fit_transform(X_train))\n",
    "X_train.index = X_train_ind\n",
    "\n",
    "X_test_ind = X_test.index\n",
    "X_test =  pd.DataFrame(mm.transform(X_test))\n",
    "X_test.index = X_test_ind\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"training accuracy: {knn.score(X_train, y_train)}\")\n",
    "print(f\"Test accuracy: {knn.score(X_test, y_test)}\")\n",
    "\n",
    "plot_confusion_matrix(estimator=knn, X=X_test, y_true=y_test, display_labels=['Perished', 'Survived']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:37.346806Z",
     "start_time": "2023-06-05T16:52:36.624776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T16:52:37.351807Z",
     "start_time": "2023-06-05T16:52:37.351807Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "precision_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Up: Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The \"closeness\" of data points â†’ proxy for similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/distances.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minkowski Distance**:\n",
    "\n",
    "$$dist(A,B) = (\\sum_{k=1}^{N} |a_k - b_k|^c)^\\frac{1}{c} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special cases of Minkowski distance are:\n",
    "\n",
    "- Manhattan: $dist(A,B) = \\sum_{k=1}^{N} |a_k - b_k|$\n",
    "\n",
    "\n",
    "- Euclidean: $dist(A,B) = \\sqrt{ \\sum_{k=1}^{N} (a_k - b_k)^2 }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few different distance [metrics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html) built-in for Scikit-learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
